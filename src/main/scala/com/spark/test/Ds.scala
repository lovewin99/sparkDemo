package com.spark.test

//import org.apache.spark.sql.SparkSession

/**
 *
 * Created by wangxy on 16-10-31.
 */
object Ds {

  def main(args: Array[String]): Unit = {

//    println("hello ")

//    val sparkSession = SparkSession.builder.
//      master("local")
//      .appName("example")
//      .getOrCreate()
//
//    import sparkSession.implicits._
//    val data = sparkSession.read.text("/home/wangxy/data/hello.txt").as[String]
//
////    val words = data.flatMap(value => value.split("\\s+"))
////
////    val groupedWords = words.groupByKey(_.toLowerCase)
////
////    val counts = groupedWords.count()
////
////    counts.show()
//
//    val words = data.flatMap(value => value.split("\\s+"))
//
////    val groupedWords = words.groupByKey(x => x).mapGroups{(k, v) => s"$k=" + v.length}.write.text("/home/wangxy/data/ds")
//
//    val t1 = words.map((_, 1))





  }

}
